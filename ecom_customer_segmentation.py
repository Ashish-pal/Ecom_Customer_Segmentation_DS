# -*- coding: utf-8 -*-
"""Ecom_Customer_Segmentation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Z5N16HB6uMHlhdyNyHls7YyFYnatu-65
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')
from google.colab import files

uploaded = files.upload()

dataset = pd.read_excel("ecom_customer_data.xlsx")

dataset.head()

dataset.shape

dataset.info()

dataset.describe()

dataset.isnull().sum()

dataset.dtypes

dataset.columns

obj = (dataset.dtypes == 'object')
object_cols = list(obj[obj].index)
print("Categorical variables:",len(object_cols))

int_ = (dataset.dtypes == 'int')
num_cols = list(int_[int_].index)
print("Integer variables:",len(num_cols))

fl = (dataset.dtypes == 'float')
fl_cols = list(fl[fl].index)
print("Float variables:",len(fl_cols))

dataset.dropna(subset=['Gender'], inplace=True)
dataset.fillna(0, inplace=True)

for column in dataset.columns:
    if dataset[column].dtype != 'object':
        Q1 = dataset[column].quantile(0.25)
        Q3 = dataset[column].quantile(0.75)
        IQR = Q3 - Q1
        dataset = dataset[(dataset[column] >= (Q1 - 1.5 * IQR)) & (dataset[column] <= (Q3 + 1.5 * IQR))]

plt.figure(figsize=(10, 6))
plt.boxplot(dataset['Orders'])
plt.title('Boxplot for Orders')
plt.ylabel('Number of Orders')
plt.show()

plt.figure(figsize=(10, 6))
plt.scatter(range(len(dataset['Orders'])), dataset['Orders'], alpha=0.5)
plt.title('Scatter Plot for Orders')
plt.xlabel('Customer Index')
plt.ylabel('Number of Orders')
plt.show()

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.impute import SimpleImputer

"""###Data Cleaning"""

#Encoding categorical variables
label_encoder = LabelEncoder()
dataset['Gender'] = label_encoder.fit_transform(dataset['Gender'])

#Handling missing values
imputer = SimpleImputer(strategy='most_frequent')
dataset['Gender'] = imputer.fit_transform(dataset[['Gender']])

#Normalizing/standardizing numerical variables if necessary
scaler = StandardScaler()
dataset.iloc[:, 2:] = scaler.fit_transform(dataset.iloc[:, 2:])

dataset.head()

"""###EDA"""

plt.figure(figsize=(10, 6))
sns.histplot(dataset['Orders'], kde=True, bins=20)
plt.title('Distribution of Orders')
plt.xlabel('Orders')
plt.ylabel('Frequency')
plt.show()

plt.figure(figsize=(12, 8))
sns.heatmap(dataset.corr(), annot=False, cmap='coolwarm')
plt.title('Correlation Heatmap')
plt.show()

"""###Model Training and Evaluation

#####Linear Regression
"""

from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

X = dataset.drop(columns=['Orders'])
y = dataset['Orders']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

linear_reg = LinearRegression()
linear_reg.fit(X_train, y_train)
y_pred = linear_reg.predict(X_test)

mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print(f'Linear Regression - Mean Squared Error: {mse}, R2 Score: {r2}')

"""####SVM"""

from sklearn.svm import SVR

svm_reg = SVR()
svm_reg.fit(X_train, y_train)

y_pred = svm_reg.predict(X_test)

mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print(f'SVM - Mean Squared Error: {mse}, R2 Score: {r2}')

"""####Random Forest"""

from sklearn.ensemble import RandomForestRegressor

rf_reg = RandomForestRegressor(n_estimators=100, random_state=42)
rf_reg.fit(X_train, y_train)

y_pred = rf_reg.predict(X_test)

mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print(f'Random Forest - Mean Squared Error: {mse}, R2 Score: {r2}')

!pip install catboost

from catboost import CatBoostRegressor
from sklearn.metrics import r2_score
cb_model = CatBoostRegressor()
cb_model.fit(X_train, y_train)
preds = cb_model.predict(X_test)

cb_r2_score = r2_score(y_test, preds)
cb_r2_score

"""###Clustering for Customer Segmentation

####PCA
"""

from sklearn.decomposition import PCA
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_scaled)

print(f"Explained variance by PCA components: {pca.explained_variance_ratio_}")

from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
summ_squared_error = []
for k in range(1, 11):
    kmeans = KMeans(n_clusters=k, random_state=0)
    kmeans.fit(X_pca)
    summ_squared_error.append(kmeans.inertia_)

plt.figure(figsize=(8, 5))
plt.plot(range(1, 11), summ_squared_error, marker='o')
plt.xlabel('Number of clusters')
plt.ylabel('Sum Squared Errors')
plt.title('Elbow Method for Optimal k')
plt.show()

silhouette_scores = []
for k in range(2, 11):
    kmeans = KMeans(n_clusters=k, random_state=0)
    labels = kmeans.fit_predict(X_pca)
    silhouette_scores.append(silhouette_score(X_pca, labels))

plt.figure(figsize=(8, 5))
plt.plot(range(2, 11), silhouette_scores, marker='o')
plt.xlabel('Number of clusters')
plt.ylabel('Silhouette Score')
plt.title('Silhouette Scores for Different k')
plt.show()

kmeans_pca = KMeans(n_clusters=5, random_state=0)
clusters = kmeans_pca.fit_predict(X_pca)
dataset['Cluster'] = clusters

plt.figure(figsize=(8, 5))
plt.scatter(X_pca[:, 0], X_pca[:, 1], c=clusters, cmap='viridis')
plt.xlabel('PCA Component 1')
plt.ylabel('PCA Component 2')
plt.title('Customer Segments (K-means Clustering)')
plt.show()

"""####KMeans without PCA"""

kmeans = KMeans(n_clusters=5, random_state=42)
clusters = kmeans.fit_predict(X)

dataset['Cluster'] = clusters

plt.figure(figsize=(10, 6))
sns.scatterplot(x=dataset['Orders'], y=dataset['Gender'], hue=dataset['Cluster'], palette='viridis')
plt.title('Customer Segments')
plt.xlabel('Orders')
plt.ylabel('Gender')
plt.show()

"""###Reporting and Visualization"""

cluster_means = dataset.groupby('Cluster').mean()
print(cluster_means)

"""###Decision Tree Regression."""

X = dataset[['Gender', 'Orders']]
y = dataset['Orders']

print("Features and Target:")
print(X)
print(y)

from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeRegressor

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)

dt_regressor = DecisionTreeRegressor(random_state=0)
dt_regressor.fit(X_train, y_train)

y_pred_dt = dt_regressor.predict(X_test)

from sklearn.metrics import r2_score, mean_squared_error

r2_dt = r2_score(y_test, y_pred_dt)
mse_dt = mean_squared_error(y_test, y_pred_dt)

print(f"Decision Tree Regression R2-Score: {r2_dt}")
print(f"Decision Tree Regression MSE: {mse_dt}")

"""###Cross-Validation

####K-Fold
"""

from sklearn.model_selection import KFold
def k_fold_validation(model, X, y, n_splits=5):
    kf = KFold(n_splits=n_splits, shuffle=True, random_state=0)
    r2_scores = []
    mse_scores = []

    for train_index, test_index in kf.split(X):
        X_train, X_test = X.iloc[train_index], X.iloc[test_index]
        y_train, y_test = y.iloc[train_index], y.iloc[test_index]

        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)

        r2_scores.append(r2_score(y_test, y_pred))
        mse_scores.append(mean_squared_error(y_test, y_pred))

    return np.mean(r2_scores), np.mean(mse_scores)


lr = LinearRegression()
lr_r2, lr_mse = k_fold_validation(lr, X, y, n_splits=5)
print(f"Linear Regression - Mean R2-Score: {lr_r2}")
print(f"Linear Regression - Mean MSE: {lr_mse} \n")


dt_regressor = DecisionTreeRegressor(random_state=0)
dt_r2, dt_mse = k_fold_validation(dt_regressor, X, y, n_splits=5)
print(f"Decision Tree Regression - Mean R2-Score: {dt_r2}")
print(f"Decision Tree Regression - Mean MSE: {dt_mse} \n")


rf_regressor = RandomForestRegressor(random_state=0)
rf_r2, rf_mse = k_fold_validation(rf_regressor, X, y, n_splits=5)
print(f"Random Forest Regression - Mean R2-Score: {rf_r2}")
print(f"Random Forest Regression - Mean MSE: {rf_mse} \n")


svm = SVR()
svm_r2, svm_mse = k_fold_validation(svm, X, y, n_splits=5)
print(f"SVM Regression - Mean R2-Score: {svm_r2}")
print(f"SVM Regression - Mean MSE: {svm_mse} \n")


kmeans_pca = KMeans()
kmeans_pca_r2, kmeans_pca_mse = k_fold_validation(kmeans_pca, X, y, n_splits=5)
print(f"Kmeans with PCA - Mean R2-Score: {svm_r2}")
print(f"Kmeans with PCA - Mean MSE: {svm_mse} \n")


kmeans_wpca = KMeans()
kmeans_wpca_r2, kmeans_wpca_mse = k_fold_validation(kmeans_wpca, X, y, n_splits=5)
print(f"Kmeans without PCA - Mean R2-Score: {svm_r2}")
print(f"Kmeans without PCA - Mean MSE: {svm_mse}")